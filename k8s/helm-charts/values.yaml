namespace: crusoe-system
environment: prod
endpoints:
  prod: "https://cms-monitoring.crusoecloud.com"
  staging: "https://cms-monitoring.crusoecloud.site"
  dev: "https://cms-monitoring.crusoecloud.xyz"

proxy:
  enabled: false
  url: "internal.cms-monitoring.crusoecloud.com"
  port: 3128

customMetrics:
  enabled: true
  namespace: crusoe-monitoring

dcgmMetrics:
  enabled: true

kubeStateMetrics:
  enabled: true

logs:
  enabled: true

job:
  name: crusoe-monitoring-token-job
  image: ghcr.io/crusoecloud/crusoe-watch-agent/token-job:v0.1.9
  ttlSecondsAfterFinished: 300
secrets:
  crusoeMonitoringToken: crusoe-monitoring-token
  existingSecret: crusoe-secrets
  useProvidedMonitoringToken: false
  monitoringToken: ""

metricsExporter:
  defaultMetricsPath: /metrics
  defaultMetricsPort: 9100
  defaultDcgmExporterPort: 9400
  defaultKubeStateMetricsPort: 8080
  defaultScrapeInterval: 60

logLevel: INFO


# CPU profile for Vector subchart
# Adjust according to https://helm.vector.dev
vector:
  enabled: true
  # Default values for Vector
  # See Vector helm documentation to learn more:
  # https://vector.dev/docs/setup/installation/package-managers/helm/

  # nameOverride -- Override the name of resources.
  nameOverride: "crusoe-watch-agent"

  # fullnameOverride -- Override the full name of resources.
  fullnameOverride: "crusoe-watch-agent"

  # role -- [Role](https://vector.dev/docs/setup/deployment/roles/) for this Vector instance, valid options are:
  # "Agent", "Aggregator", and "Stateless-Aggregator".

  # Each role is created with the following workloads:
  # Agent = DaemonSet
  # Aggregator = StatefulSet
  # Stateless-Aggregator = Deployment
  role: "Agent"

  # rollWorkload -- Add a checksum of the generated ConfigMap to workload annotations.
  rollWorkload: true

  # rollWorkloadSecrets -- Add a checksum of the generated Secret to workload annotations.
  rollWorkloadSecrets: false

  # rollWorkloadExtraObjects -- Add a checksum of the generated ExtraObjects to workload annotations.
  rollWorkloadExtraObjects: false

  # Additional labels to add to all resources
  # commonLabels:
  #   app.kubernetes.io/component: agent

  # Define the Vector image to use.
  image:
    # image.repository -- Override default registry and name for Vector's image.
    repository: timberio/vector
    # image.pullPolicy -- The [pullPolicy](https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy) for
    # Vector's image.
    pullPolicy: IfNotPresent
    # image.pullSecrets -- The [imagePullSecrets](https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod)
    # to reference for the Vector Pods.
    pullSecrets: [ ]
    # image.tag -- The tag to use for Vector's image.
    # @default -- Derived from the Chart's appVersion.
    tag: "nightly-debian"
    # image.sha -- The SHA to use for Vector's image.
    sha: ""
    # image.base -- The base distribution to use for vector. If set, then the base in appVersion will be replaced with this base alongside the version.
    # For example: with a `base` of `debian` `0.38.0-distroless-libc` becomes `0.38.0-debian`
    base: ""

  # replicas -- Specify the number of Pods to create. Valid for the "Aggregator" and "Stateless-Aggregator" roles.
  replicas: 1

  # Adding additional entries with hostAliases
  hostAliases: [ ]
  # - ip: "127.0.0.1"
  #   hostnames:
  #   - "foo.local"
  #   - "bar.local"


  # podManagementPolicy -- Specify the [podManagementPolicy](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies)
  # for the StatefulSet. Valid for the "Aggregator" role.
  podManagementPolicy: OrderedReady

  # Create a Secret resource for Vector to use.
  secrets:
    # secrets.generic -- Each Key/Value will be added to the Secret's data key, each value should be raw and NOT base64
    # encoded. Any secrets can be provided here. It's commonly used for credentials and other access related values.
    # **NOTE: Don't commit unencrypted secrets to git!**
    generic: { }
      # my_variable: "my-secret-value"
      # datadog_api_key: "api-key"
    # awsAccessKeyId: "access-key"
    # awsSecretAccessKey: "secret-access-key"

  autoscaling:
    # autoscaling.enabled -- Create a [HorizontalPodAutoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
    # for Vector. Valid for the "Aggregator" and "Stateless-Aggregator" roles.
    enabled: false
    # autoscaling.external -- Set to `true` if using an external autoscaler like [KEDA](https://keda.sh/).
    # Valid for the "Aggregator and "Stateless-Aggregator" roles.
    external: false
    # autoscaling.annotations -- Annotations to add to Vector's HPA.
    annotations: { }
    # autoscaling.minReplicas -- Minimum replicas for Vector's HPA.
    minReplicas: 1
    # autoscaling.maxReplicas -- Maximum replicas for Vector's HPA.
    maxReplicas: 10
    # autoscaling.targetCPUUtilizationPercentage -- Target CPU utilization for Vector's HPA.
    targetCPUUtilizationPercentage: 80
    # autoscaling.targetMemoryUtilizationPercentage -- (int) Target memory utilization for Vector's HPA.
    targetMemoryUtilizationPercentage:
    # autoscaling.customMetric -- Target a custom metric for autoscaling.
    customMetric: { }
      #  - type: Pods
      #    pods:
      #      metric:
      #        name: utilization
      #      target:
    #        type: AverageValue
    #        averageValue: 95
    # autoscaling.behavior -- Configure separate scale-up and scale-down behaviors.
    behavior: { }
    # scaleDown:
    #   stabilizationWindowSeconds: 300

  podDisruptionBudget:
    # podDisruptionBudget.enabled -- Enable a [PodDisruptionBudget](https://kubernetes.io/docs/tasks/run-application/configure-pdb/)
    # for Vector.
    enabled: false
    # podDisruptionBudget.minAvailable -- The number of Pods that must still be available after an eviction.
    minAvailable: 1
    # podDisruptionBudget.maxUnavailable -- (int) The number of Pods that can be unavailable after an eviction.
    maxUnavailable:

  rbac:
    # rbac.create -- If true, create and use RBAC resources. Only valid for the "Agent" role.
    create: true

  psp:
    # psp.create -- If true, create a [PodSecurityPolicy](https://kubernetes.io/docs/concepts/security/pod-security-policy/)
    # resource. PodSecurityPolicy is deprecated as of Kubernetes v1.21, and will be removed in v1.25. Intended for use
    # with the "Agent" role.
    create: false

  serviceAccount:
    # serviceAccount.create -- If true, create a ServiceAccount for Vector.
    create: true
    # serviceAccount.annotations -- Annotations to add to Vector's ServiceAccount.
    annotations: { }
    # serviceAccount.name -- The name of the ServiceAccount to use. If not set and serviceAccount.create is true, a name
    # is generated using the fullname template.
    name:
    # serviceAccount.automountToken -- Automount API credentials for Vector's ServiceAccount.
    automountToken: true

  # podAnnotations -- Set annotations on Vector Pods.
  podAnnotations: { }

  # podLabels -- Set labels on Vector Pods.
  podLabels:
    vector.dev/exclude: "true"

  # podPriorityClassName -- Set the [priorityClassName](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass)
  # on Vector Pods.
  podPriorityClassName: ""

  # podHostNetwork -- Configure hostNetwork on Vector Pods.
  podHostNetwork: true

  # podSecurityContext -- Allows you to overwrite the default [PodSecurityContext](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/)
  # for Vector Pods.
  podSecurityContext: { }

  # workloadResourceAnnotations -- Set annotations on the Vector DaemonSet, Deployment or StatefulSet.
  workloadResourceAnnotations: { }

  # securityContext -- Specify securityContext on Vector containers.
  securityContext:
    privileged: true

  # command -- Override Vector's default command.
  command: [
    "/bin/sh",
    "-c",
    "export VM_ID=$(cat /host/sys/class/dmi/id/product_uuid) && /usr/bin/vector --config /etc/vector/vector.yaml --watch-config"
  ]

  # args -- Override Vector's default arguments.
  args:
    - --config-dir
    - "/etc/vector/"

  # env -- Set environment variables for Vector containers.
  env:
    - name: CRUSOE_MONITORING_TOKEN
      valueFrom:
        secretKeyRef:
          name: crusoe-monitoring-token
          key: CRUSOE_MONITORING_TOKEN
    - name: CHART_VERSION
      valueFrom:
        configMapKeyRef:
          name: crusoe-watch-agent-metadata
          key: chart-version
    - name: CHART_NAME
      valueFrom:
        configMapKeyRef:
          name: crusoe-watch-agent-metadata
          key: chart-name

  # envFrom -- Define environment variables from Secrets or ConfigMaps.
  envFrom:
    - secretRef:
        name: crusoe-secrets

  # containerPorts -- Manually define Vector's containerPorts, overriding automated generation of containerPorts.
  containerPorts: [ ]

  # resources -- Set Vector resource requests and limits.
  resources: { }
    # requests:
    #   cpu: 200m
    #   memory: 256Mi
    # limits:
  #   cpu: 200m
  #   memory: 256Mi

  # lifecycle -- Set lifecycle hooks for Vector containers.
  lifecycle: { }
    # preStop:
    #   exec:
    #     command:
  #     - /bin/sleep
  #     - "10"


  # minReadySeconds -- Specify the minimum number of seconds a newly spun up pod should wait to
  # pass healthchecks before it is considered available.
  minReadySeconds: 0

  # updateStrategy -- Customize the updateStrategy used to replace Vector Pods, this is also used for the
  # DeploymentStrategy for the "Stateless-Aggregators". Valid options depend on the chosen role.

  # Agent (DaemonSetUpdateStrategy): https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/daemon-set-v1/#DaemonSetSpec)
  # Aggregator (StatefulSetUpdateStrategy): https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/stateful-set-v1/#StatefulSetSpec
  # Stateless-Aggregator (DeploymentStrategy): https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/
  updateStrategy: { }
  #   type: RollingUpdate
  #   rollingUpdate:
  #     maxUnavailable: 1

  # terminationGracePeriodSeconds -- Override Vector's terminationGracePeriodSeconds.
  terminationGracePeriodSeconds: 60

  # nodeSelector -- Configure a [nodeSelector](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector)
  # for Vector Pods.
  nodeSelector: { }

  # tolerations -- Configure Vector Pods to be scheduled on [tainted](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
  # nodes.
  tolerations: [ ]

  # affinity -- Configure [affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity)
  # rules for Vector Pods.
  affinity: { }

  # topologySpreadConstraints -- Configure [topology spread constraints](https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/)
  # for Vector Pods. Valid for the "Aggregator" and "Stateless-Aggregator" roles.
  topologySpreadConstraints: [ ]

  # Configuration for Vector's Service.
  service:
    # service.enabled -- If true, create and provide a Service resource for Vector.
    enabled: false
    # service.type -- Set the type for Vector's Service.
    type: "ClusterIP"
    # service.annotations -- Set annotations on Vector's Service.
    annotations: { }
    # service.topologyKeys -- Specify the [topologyKeys](https://kubernetes.io/docs/concepts/services-networking/service-topology/#using-service-topology)
    # field on Vector's Service.
    topologyKeys: [ ]
    #   - "kubernetes.io/hostname"
    #   - "topology.kubernetes.io/zone"
    #   - "topology.kubernetes.io/region"
    #   - "*"
    # service.ports -- Manually set the Service ports, overriding automated generation of Service ports.
    ports: [ ]
    # service.externalTrafficPolicy -- Specify the [externalTrafficPolicy](https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip).
    externalTrafficPolicy: ""
    # service.internalTrafficPolicy -- Specify the [internalTrafficPolicy](https://kubernetes.io/docs/concepts/services-networking/service-traffic-policy).
    internalTrafficPolicy: ""
    # service.loadBalancerIP -- Specify the [loadBalancerIP](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer).
    loadBalancerIP: ""
    # service.ipFamilyPolicy -- Configure [IPv4/IPv6 dual-stack](https://kubernetes.io/docs/concepts/services-networking/dual-stack/).
    ipFamilyPolicy: ""
    # service.ipFamilies -- Configure [IPv4/IPv6 dual-stack](https://kubernetes.io/docs/concepts/services-networking/dual-stack/).
    ipFamilies: [ ]

  # Configuration for Vector's Headless Service.
  serviceHeadless:
    # serviceHeadless.enabled -- If true, create and provide a Headless Service resource for Vector.
    enabled: false

  # Configuration for Vector's Ingress.
  ingress:
    # ingress.enabled -- If true, create and use an Ingress resource.
    enabled: false
    # ingress.className -- Specify the [ingressClassName](https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress),
    # requires Kubernetes >= 1.18
    className: ""
    # ingress.annotations -- Set annotations on the Ingress.
    annotations: { }
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    # ingress.hosts -- Configure the hosts and paths for the Ingress.
    hosts: [ ]
    #  - host: chart-example.local
    #    paths:
    #      - path: /
    #        pathType: ImplementationSpecific
    #        # Specify the port name or number on the Service
    #        # Using name requires Kubernetes >=1.19
    #        port:
    #          name: ""
    #          number: ""
    # ingress.tls -- Configure TLS for the Ingress.
    tls: [ ]
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  # existingConfigMaps -- List of existing ConfigMaps for Vector's configuration instead of creating a new one. Requires
  # dataDir to be set. Additionally, containerPorts, service.ports, and serviceHeadless.ports should be specified based on
  # your supplied configuration. If set, this parameter takes precedence over customConfig and the chart's default configs.
  existingConfigMaps: [ ]

  # dataDir -- Specify the path for Vector's data, only used when existingConfigMaps are used.
  dataDir: ""

  # customConfig -- Override Vector's default configs, if used **all** options need to be specified. This section supports
  # using helm templates to populate dynamic values. See Vector's [configuration documentation](https://vector.dev/docs/reference/configuration/)
  # for all options.
  customConfig:
    data_dir: /vector-data-dir
    sources:
      host_metrics:
        type: host_metrics
        collectors:
          - cpu
          - disk
          - host
          - memory
          - network
          - process
        network:
          devices:
            excludes:
              - "lo*"
            includes:
              - "ens*"
        process:
          processes:
            includes:
              - "vector"
        scrape_interval_secs: 60
      internal_metrics:
        type: internal_metrics
        scrape_interval_secs: 60

    transforms:
      enrich_node_metrics:
        type: remap
        inputs:
          - host_metrics
        source: |
          if exists(.tags.Hostname) {
            parts, _ = split(.tags.Hostname, ".")
            host_prefix = get(parts, [0]) ?? ""

            prefix_parts, _ = split(host_prefix, "-")
            nodepool_id_parts, _ = slice(prefix_parts, 0, length(prefix_parts) - 1)

            .tags.nodepool, _ = join(nodepool_id_parts, "-")
          }
          .tags.cluster_id = "${CRUSOE_CLUSTER_ID}"
          .tags.vm_id = "${VM_ID}"
          .tags.crusoe_resource = "vm"

      filter_internal_metrics:
        type: filter
        inputs:
            - internal_metrics
        condition: |
            includes(
                [
                    "vector_buffer_byte_size",
                    "vector_buffer_discarded_events_total",
                    "vector_buffer_events",
                    "vector_buffer_received_events_total",
                    "vector_buffer_send_duration_seconds",
                    "vector_buffer_sent_events_total",
                    "vector_build_info",
                    "vector_collect_completed_total",
                    "vector_collect_duration_seconds",
                    "vector_component_discarded_events_total",
                    "vector_component_errors_total",
                    "vector_component_received_events_total",
                    "vector_component_sent_events_total",
                    "vector_config_reload_rejected",
                    "vector_config_reloaded",
                    "vector_connection_established_total",
                    "vector_connection_send_errors_total",
                    "vector_http_client_requests_sent_total",
                    "vector_http_client_response_rtt_seconds",
                    "vector_http_client_responses_total",
                    "vector_http_client_rtt_seconds",
                    "vector_internal_metrics_cardinality",
                    "vector_open_connections",
                    "vector_open_files",
                    "vector_source_lag_time_seconds",
                    "vector_uptime_seconds",
                ],
                .name,
            )

      add_internal_labels:
        type: remap
        inputs:
            - filter_internal_metrics
        source: |
            .tags.cluster_id = "${CRUSOE_CLUSTER_ID}"
            .tags.vm_id = "${VM_ID}"
            .tags.crusoe_resource = "vm"
            .tags.chart_name = "${CHART_NAME}"
            .tags.chart_version = "${CHART_VERSION}"

    sinks:
      cms_gateway_node_metrics:
        type: prometheus_remote_write
        inputs:
          - enrich_node_metrics
          - add_internal_labels
        endpoint: "https://cms-monitoring.crusoecloud.com/ingest"
        tenant_id: "cri:vm/${VM_ID}"
        auth:
          strategy: bearer
          token: "${CRUSOE_MONITORING_TOKEN}"
        healthcheck:
          enabled: false
        request:
          concurrency: adaptive
        batch:
            max_bytes: 500000 # ~500KB
        compression: snappy
        tls:
          verify_certificate: true
          verify_hostname: true
  # defaultVolumes -- Default volumes that are mounted into pods. In most cases, these should not be changed.
  # Use `extraVolumes`/`extraVolumeMounts` for additional custom volumes.
  # @default -- See `values.yaml`
  defaultVolumes:
    - name: var-log
      hostPath:
        path: "/var/log/"
    - name: var-lib
      hostPath:
        path: "/var/lib/"
    - name: procfs
      hostPath:
        path: "/proc"
    - name: sysfs
      hostPath:
        path: "/sys"
    - name: dev-kmsg
      hostPath:
        path: "/dev/kmsg"
        type: CharDevice

  # defaultVolumeMounts -- Default volume mounts. Corresponds to `volumes`.
  # @default -- See `values.yaml`
  defaultVolumeMounts:
    - name: var-log
      mountPath: "/var/log/"
      readOnly: true
    - name: var-lib
      mountPath: "/var/lib"
      readOnly: true
    - name: procfs
      mountPath: "/host/proc"
      readOnly: true
    - name: sysfs
      mountPath: "/host/sys"
      readOnly: true
    - name: dev-kmsg
      mountPath: "/dev/kmsg"
      readOnly: true

  # extraVolumes -- Additional Volumes to use with Vector Pods.
  extraVolumes:
    - name: journal-logs
      hostPath:
        path: /var/log/journal
    - name: nvidia-bug-reports
      hostPath:
        path: /var/log/nvidia-bug-reports
    - name: vector-config   # shared writable config
      emptyDir: { }
    - name: base-config     # mount your existing configmap
      configMap:
        name: crusoe-watch-agent
    - name: reloader-config
      configMap:
        name: vector-reloader-config

  # extraVolumeMounts -- Additional Volume to mount into Vector Containers.
  extraVolumeMounts:
    - name: journal-logs
      mountPath: /var/log/journal
      readOnly: true
    - name: nvidia-bug-reports
      mountPath: /var/log/nvidia-bug-reports
      readOnly: false
    - name: vector-config
      mountPath: /etc/vector
    - name: base-config
      mountPath: /etc/vector-base
      readOnly: true
    - name: reloader-config
      mountPath: /etc/reloader
      readOnly: true

  # initContainers -- Init Containers to be added to the Vector Pods.
  # This also supports template content, which will eventually be converted to yaml.
  initContainers: [ ]
  # initContainers:
  #   - name: test
  #     image: busybox:latest
  #     command:
  #       - cp
  #     args:
  #       - /bin/sleep
  #       - /test/sleep
  #     volumeMounts:
  #       - name: test
  #         mountPath: /test

  # extraContainers -- Extra Containers to be added to the Vector Pods.
  # This also supports template content, which will eventually be converted to yaml.
  extraContainers:
    - name: vector-config-reloader
      image: ghcr.io/crusoecloud/crusoe-watch-agent/vector-config-reloader:v0.2.6
      env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
      volumeMounts:
        - name: vector-config
          mountPath: /etc/vector
        - name: base-config
          mountPath: /etc/vector-base
          readOnly: true
        - name: reloader-config
          mountPath: /etc/reloader
      resources:
        requests:
          cpu: 50m
          memory: 64Mi

  # Configuration for Vector's data persistence.
  persistence:
    # persistence.enabled -- If true, create and use PersistentVolumeClaims.
    enabled: false
    # persistence.existingClaim -- Name of an existing PersistentVolumeClaim to use. Valid for the "Aggregator" role.
    existingClaim: ""
    # persistence.storageClassName -- Specifies the storageClassName for PersistentVolumeClaims. Valid for the
    # "Aggregator" role.
    # storageClassName: default

    # persistence.retentionPolicy -- Configure a [PersistentVolumeClaimRetentionPolicy](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention)
    # for Vector's PersistentVolumeClaims. Valid for the "Aggregator" role.
    retentionPolicy: { }
    #  whenDeleted: Retain
    #  whenScaled: Retain

    # persistence.accessModes -- Specifies the accessModes for PersistentVolumeClaims. Valid for the "Aggregator" role.
    accessModes:
      - ReadWriteOnce
    # persistence.size -- Specifies the size of PersistentVolumeClaims. Valid for the "Aggregator" role.
    size: 10Gi
    # persistence.finalizers -- Specifies the finalizers of PersistentVolumeClaims. Valid for the "Aggregator" role.
    finalizers:
      - kubernetes.io/pvc-protection
    # persistence.selectors -- Specifies the selectors for PersistentVolumeClaims. Valid for the "Aggregator" role.
    selectors: { }

    hostPath:
      # persistence.hostPath.enabled -- If true, use hostPath persistence. Valid for the "Agent" role, if it's disabled
      # the "Agent" role will use emptyDir.
      enabled: true
      # persistence.hostPath.path -- Override path used for hostPath persistence. Valid for the "Agent" role, persistence
      # is always used for the "Agent" role.
      path: "/var/lib/vector"

  # dnsPolicy -- Specify the [dnsPolicy](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy)
  # for Vector Pods.
  dnsPolicy: ClusterFirst

  # dnsConfig -- Specify the [dnsConfig](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-dns-config)
  # options for Vector Pods.
  dnsConfig: { }
    # nameservers:
    #   - 1.2.3.4
    # searches:
    #   - ns1.svc.cluster-domain.example
    #   - my.dns.search.suffix
    # options:
    #   - name: ndots
  #     value: "2"
  #   - name: edns0

  # shareProcessNamespace -- Specify the [shareProcessNamespace](https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/)
  # options for Vector Pods.
  shareProcessNamespace: false

  # livenessProbe -- Override default liveness probe settings. If customConfig is used, requires customConfig.api.enabled
  # to be set to true.
  livenessProbe: { }
    # httpGet:
  #   path: /health
  #   port: api

  # readinessProbe -- Override default readiness probe settings. If customConfig is used,
  # requires customConfig.api.enabled to be set to true.
  readinessProbe: { }
    # httpGet:
  #   path: /health
  #   port: api

  # Configure a PodMonitor for Vector, requires the PodMonitor CRD to be installed.
  podMonitor:
    # podMonitor.enabled -- If true, create a PodMonitor for Vector.
    enabled: false
    # podMonitor.jobLabel -- Override the label to retrieve the job name from.
    jobLabel: app.kubernetes.io/name
    # podMonitor.port -- Override the port to scrape.
    port: prom-exporter
    # podMonitor.path -- Override the path to scrape.
    path: /metrics
    # podMonitor.interval -- Override the interval at which metrics should be scraped.
    interval:
    # podMonitor.scrapeTimeout -- Override the timeout after which the scrape is ended.
    scrapeTimeout:
    # podMonitor.relabelings -- [RelabelConfigs](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config)
    # to apply to samples before scraping.
    relabelings: [ ]
    # podMonitor.metricRelabelings -- [MetricRelabelConfigs](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs)
    # to apply to samples before ingestion.
    metricRelabelings: [ ]
    # podMonitor.podTargetLabels -- [podTargetLabels](https://prometheus-operator.dev/docs/operator/api/#monitoring.coreos.com/v1.PodMonitorSpec)
    # transfers labels on the Kubernetes Pod onto the target.
    podTargetLabels: [ ]
    # podMonitor.additionalLabels -- Adds additional labels to the PodMonitor.
    additionalLabels: { }
    # podMonitor.honorLabels -- If true, honor_labels is set to true in the [scrape config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config).
    honorLabels: false
    # podMonitor.honorTimestamps -- If true, honor_timestamps is set to true in the [scrape config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config).
    honorTimestamps: true

  # Log level for Vector.
  logLevel: "info"

  # Optional built-in HAProxy load balancer.
  haproxy:
    # haproxy.enabled -- If true, create a HAProxy load balancer.
    enabled: false

    # Define the HAProxy image to use.
    image:
      # haproxy.image.repository -- Override default registry and name for HAProxy.
      repository: haproxytech/haproxy-alpine
      # haproxy.image.pullPolicy -- HAProxy image pullPolicy.
      pullPolicy: IfNotPresent
      # haproxy.image.pullSecrets -- The [imagePullSecrets](https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod)
      # to reference for the HAProxy Pods.
      pullSecrets: [ ]
      # haproxy.image.tag -- The tag to use for HAProxy's image.
      tag: "2.6.12"

    # haproxy.rollWorkload -- Add a checksum of the generated ConfigMap to the HAProxy Deployment.
    rollWorkload: true

    # haproxy.replicas -- Set the number of HAProxy Pods to create.
    replicas: 1

    serviceAccount:
      # haproxy.serviceAccount.create -- If true, create a HAProxy ServiceAccount.
      create: true
      # haproxy.serviceAccount.annotations -- Annotations to add to the HAProxy ServiceAccount.
      annotations: { }
      # haproxy.serviceAccount.name -- The name of the HAProxy ServiceAccount to use. If not set and create is true, a
      # name is generated using the fullname template.
      name:
      # haproxy.serviceAccount.automountToken -- Automount API credentials for the HAProxy ServiceAccount.
      automountToken: true

    # haproxy.strategy -- Customize the [strategy](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/)
    # used to replace HAProxy Pods.
    strategy: { }
      # rollingUpdate:
      #   maxSurge: 25%
    #   maxUnavailable: 25%
    # type: RollingUpdate

    # haproxy.terminationGracePeriodSeconds -- Override HAProxy's terminationGracePeriodSeconds.
    terminationGracePeriodSeconds: 60

    # haproxy.podAnnotations -- Set annotations on HAProxy Pods.
    podAnnotations: { }

    # haproxy.podLabels -- Set labels on HAProxy Pods.
    podLabels: { }

    # haproxy.podPriorityClassName -- Set the priorityClassName on HAProxy Pods.
    podPriorityClassName: ""

    # haproxy.podSecurityContext -- Allows you to overwrite the default PodSecurityContext for HAProxy.
    podSecurityContext: { }
    # fsGroup: 2000

    # haproxy.securityContext -- Specify securityContext on HAProxy containers.
    securityContext: { }
      # capabilities:
      #   drop:
      #   - ALL
      # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

    # haproxy.containerPorts -- Manually define HAProxy's containerPorts, overrides automated generation of containerPorts.
    containerPorts: [ ]

    # HAProxy's Service configuration.
    service:
      # haproxy.service.type -- Set type of HAProxy's Service.
      type: ClusterIP
      # haproxy.service.annotations -- Set annotations on HAProxy's Service.
      annotations: { }
      # haproxy.service.topologyKeys -- Specify the [topologyKeys](https://kubernetes.io/docs/concepts/services-networking/service-topology/#using-service-topology)
      # field on HAProxy's Service spec.
      topologyKeys: [ ]
      #   - "kubernetes.io/hostname"
      #   - "topology.kubernetes.io/zone"
      #   - "topology.kubernetes.io/region"
      #   - "*"
      # haproxy.service.ports -- Manually set HAPRoxy's Service ports, overrides automated generation of Service ports.
      ports: [ ]
      # haproxy.service.externalTrafficPolicy -- Specify the [externalTrafficPolicy](https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip).
      externalTrafficPolicy: ""
      # haproxy.service.loadBalancerIP -- Specify the [loadBalancerIP](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer).
      loadBalancerIP: ""
      # haproxy.service.ipFamilyPolicy -- Configure [IPv4/IPv6 dual-stack](https://kubernetes.io/docs/concepts/services-networking/dual-stack/).
      ipFamilyPolicy: ""
      # haproxy.service.ipFamilies -- Configure [IPv4/IPv6 dual-stack](https://kubernetes.io/docs/concepts/services-networking/dual-stack/).
      ipFamilies: [ ]

    # haproxy.existingConfigMap -- Use this existing ConfigMap for HAProxy's configuration instead of creating a new one.
    # Additionally, haproxy.containerPorts and haproxy.service.ports should be specified based on your supplied
    # configuration. If set, this parameter takes precedence over customConfig and the chart's default configs.
    existingConfigMap: ""

    # haproxy.customConfig -- Override HAProxy's default configs, if used **all** options need to be specified.
    # This parameter supports using Helm templates to insert values dynamically. By default, this chart will parse
    # Vector's configuration from customConfig to generate HAProxy's config, which can be overwritten with
    # haproxy.customConfig.
    customConfig: ""

    # haproxy.extraVolumes -- Additional Volumes to use with HAProxy Pods.
    extraVolumes: [ ]

    # haproxy.extraVolumeMounts -- Additional Volume to mount into HAProxy Containers.
    extraVolumeMounts: [ ]

    # haproxy.initContainers -- Init Containers to be added to the HAProxy Pods.
    # This also supports template content, which will eventually be converted to yaml.
    initContainers: [ ]

    # haproxy.extraContainers -- Extra Containers to be added to the HAProxy Pods.
    # This also supports template content, which will eventually be converted to yaml.
    extraContainers: [ ]

    autoscaling:
      # haproxy.autoscaling.enabled -- Create a HorizontalPodAutoscaler for HAProxy.
      enabled: false
      # haproxy.autoscaling.external -- HAProxy is controlled by an external HorizontalPodAutoscaler.
      external: false
      # haproxy.autoscaling.minReplicas -- Minimum replicas for HAProxy's HPA.
      minReplicas: 1
      # haproxy.autoscaling.maxReplicas -- Maximum replicas for HAProxy's HPA.
      maxReplicas: 10
      # haproxy.autoscaling.targetCPUUtilizationPercentage -- Target CPU utilization for HAProxy's HPA.
      targetCPUUtilizationPercentage: 80
      # haproxy.autoscaling.targetMemoryUtilizationPercentage -- (int) Target memory utilization for HAProxy's HPA.
      targetMemoryUtilizationPercentage:
      # haproxy.autoscaling.customMetric -- Target a custom metric for autoscaling.
      customMetric: { }
        #  - type: Pods
        #    pods:
        #      metric:
        #        name: utilization
        #      target:
      #        type: AverageValue
      #        averageValue: 95

    # haproxy.resources -- Set HAProxy resource requests and limits.
    resources: { }
      # limits:
      #   cpu: 100m
      #   memory: 128Mi
      # requests:
    #   cpu: 100m
    #   memory: 128Mi

    # haproxy.livenessProbe -- Override default HAProxy liveness probe settings.
    livenessProbe:
      tcpSocket:
        port: 1024

    # haproxy.readinessProbe -- Override default HAProxy readiness probe settings.
    readinessProbe:
      tcpSocket:
        port: 1024

    # haproxy.nodeSelector -- Configure a [nodeSelector](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector)
    # for HAProxy Pods
    nodeSelector: { }

    # haproxy.tolerations -- Configure HAProxy Pods to be scheduled on [tainted](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
    # nodes.
    tolerations: [ ]

    # haproxy.affinity -- Configure [affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity)
    # rules for HAProxy Pods.
    affinity: { }

  # extraObjects -- Create extra manifests via values. Would be passed through `tpl` for templating.
  extraObjects: [ ]
    # - apiVersion: v1
    #   kind: ConfigMap
    #   metadata:
    #     name: vector-dashboards
    #     labels:
    #       grafana_dashboard: "1"
    #   data:
  #     vector.json: |
  #       {{ .Files.Get "dashboards/vector.json" | fromJson | toJson }}

# NVIDIA Log Collector configuration
logCollector:
  enabled: true
  name: crusoe-log-collector

  image:
    repository: ghcr.io/crusoecloud/crusoe-watch-agent/log-collector
    tag: v0.2.7
    pullPolicy: IfNotPresent

  # Environment variables for log collector
  env:
    LOG_OUTPUT_DIR: "/logs"
    NVIDIA_NAMESPACE: "nvidia-gpu-operator"
    NVIDIA_DRIVER_POD_PREFIX: "nvidia-gpu-driver"
    COLLECTION_INTERVAL: "3600"
    RUN_ONCE: "false"
    LOG_LEVEL: "INFO"
    MAX_LOGS_TO_KEEP: "1"
    API_ENABLED: "true"
    API_BASE_URL: "https://cms-monitoring.crusoecloud.com"
    API_POLL_INTERVAL: "60"
    COLLECTION_TIMEOUT: "300"

  # Schedule on GPU nodes only
  # Comment out to deploy on all nodes for testing
  nodeSelector: {}
    # nvidia.com/gpu: "true"

  # Tolerations for GPU nodes
  tolerations:
    - key: nvidia.com/gpu
      operator: Exists
      effect: NoSchedule

  # Init container to fix permissions
  initContainers:
    - name: fix-nvidia-logs-permissions
      image: busybox:latest
      command:
        - sh
        - -c
        - |
          mkdir -p /logs
          chown -R 0:0 /logs
          chmod -R 755 /logs
      volumeMounts:
        - name: nvidia-logs
          mountPath: /logs
      securityContext:
        runAsUser: 0

  # Volume mounts for log collector
  volumeMounts:
    - name: nvidia-logs
      mountPath: /logs
    - name: sysfs
      mountPath: /host/sys
      readOnly: true

  # Volumes
  volumes:
    - name: nvidia-logs
      hostPath:
        path: /var/log/nvidia-bug-reports
        type: DirectoryOrCreate
    - name: sysfs
      hostPath:
        path: /sys

  # Resources
  resources:
    requests:
      cpu: 50m
      memory: 256Mi
    limits:
      cpu: 200m
      memory: 512Mi

  # Security context
  # Note: Running as root (UID 0) to read /host/sys/class/dmi/id/product_uuid for VM_ID
  # and to access host paths for NVIDIA log collection
  securityContext:
    runAsUser: 0
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
